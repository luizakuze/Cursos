{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Leakage - Vazamento de Dados\n",
    "\n",
    "## 1) Definição Geral\n",
    "- Quando alguém pega os dados de uma pessoa, não necessariamente no momento da divulgação indevida de dados.\n",
    "\n",
    "## 2) Definição Contexto Machine Learning\n",
    "- Quando os dados de treinamento tem informações sobre o target (alvo), mas esses dados não estarão disponíveis para o modelo fazer a previsão.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -> Vazamento Alvo - Target Leakage\n",
    "Ele ocorre quando informações que não estariam disponíveis no momento da previsão são incluídas no modelo, levando a uma performance otimista e irrealista durante a fase de treinamento, mas a uma performance inferior durante a implantação.\n",
    "\n",
    "## Prevenção\n",
    "\n",
    "- Separar dados de treinamento e teste\n",
    "- Evitar variáveis que tem relacionamento direto com o alvo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -> Contaminação dos dados de teste/treinamento - Train-Test Contamination\n",
    "Ocorre quando informações dos dados de teste são acidentalmente expostas aos dados de treinamento durante a fase de modelagem. \n",
    "\n",
    "## Prevenção\n",
    "\n",
    "- Pipelines\n",
    "- Validação cruzada"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
