{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost\n",
    "\n",
    "- Vantagem: Conjuntos de Dados de Médio a Grande Porte - O XGBoost tende a funcionar melhor em conjuntos de dados grandes, onde pode lidar com eficiência com muitas características e amostras.\n",
    "- Tem muitos parâmetros sensíveis que podem mudar drasticamente o modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosted Decision Tree\n",
    "\n",
    "- É baseado na diferença do que a árvore anterior errou\n",
    "- learning_rate = 0.1 (ex.)\n",
    "- previsão = learning_rate * arv1 + learning_rate * arv2\n",
    "- A ideia de treinar a partir dos erros anteriores: _Boost_\n",
    "- Uma implementação do Boost, o que você tenta treinar se baseia na derivada do erro anterior: _Gradient_ <br> **Obs:** Existem outros tipos de Boost.\n",
    "\n",
    "### Árvore 1 \n",
    "```\n",
    "ex1 - 100 -> 100 \n",
    "ex2 - 120 -> 100\n",
    "ex3 - 150 -> 130\n",
    "ex4 - 80  -> 70\n",
    "ex5 - 50  -> 60\n",
    "```\n",
    "\n",
    "### Árvore 2 \n",
    "\n",
    "```\n",
    "ex1 - (100-100) = 0   -> 10\n",
    "ex2 - (120-100) = 20  -> 10\n",
    "ex3 - (150-130) = 20  -> 20\n",
    "ex4 - (80-70)   = 10  -> 0\n",
    "ex5 - (50-60)   = -10 -> -5\n",
    "```\n",
    "\n",
    "### Árvore 3\n",
    "\n",
    "```\n",
    "ex1 - (10+100-100) = -10  -> 5 \n",
    "ex2 - (10+100-120) = -10  -> -3\n",
    "ex3 - (20+130-150) =  0   -> (...)\n",
    "ex4 - (0+70-80)    = -10  -> \n",
    "ex5 - (-5+60-50)   = -5   -> \n",
    "```\n",
    "\n",
    "y real = 100 <br>\n",
    "arv1 = 100<br>\n",
    "arv2 = 10<br>\n",
    "previsão xgboost, gbdt -> 110<br>\n",
    "ou seja, com o passar das árvores cada árvore vai tendo menos importância. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colocando em prática"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemplo 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"./sample_data/california_housing_train.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bibliotecas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fazendo previsões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(\"median_house_value\", axis=1)\n",
    "y = data['median_house_value']\n",
    "\n",
    "Xtr, Xval, ytr, yval = train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "\n",
    "arveres_poderosas = XGBRegressor(learning_rate=0.08, \n",
    "                                 n_estimators=1300,\n",
    "                                 max_depth=6,\n",
    "                                 min_child_weight=1,\n",
    "                                 subsample=0.75,\n",
    "                                 colsample_bynode=0.5,\n",
    "                                 random_state=0,\n",
    "                                 #gpu_id='0',\n",
    "                                 #tree_method='gpu_hist',\n",
    "                                 #num_parallel_tree=3,\n",
    "                                 booster=\"gbtree\",\n",
    "                                 objective='reg:squarederror'\n",
    "                                 )\n",
    "arveres_poderosas.fit(Xtr, ytr)\n",
    "\n",
    "p = arveres_poderosas.predict(Xval)\n",
    "\n",
    "np.sqrt(mean_squared_error(yval, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemplo 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedimento padrão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "data = pd.read_csv('../input/train.csv')\n",
    "data.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "y = data.SalePrice\n",
    "X = data.drop(['SalePrice'], axis=1).select_dtypes(exclude=['object'])\n",
    "train_X, test_X, train_y, test_y = train_test_split(X.as_matrix(), y.as_matrix(), test_size=0.25)\n",
    "\n",
    "my_imputer = Imputer()\n",
    "train_X = my_imputer.fit_transform(train_X)\n",
    "test_X = my_imputer.transform(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajustando modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "my_model = XGBRegressor()\n",
    "# Add silent=True to avoid printing out updates with each cycle\n",
    "my_model.fit(train_X, train_y, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previsões e MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "predictions = my_model.predict(test_X)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print(\"Mean Absolute Error : \" + str(mean_absolute_error(predictions, test_y)))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
