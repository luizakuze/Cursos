{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passo a Passo - Básico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ler arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"...\"\n",
    "data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escolher o \"alvo\" (prediction target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.nome_coluna_alvo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escolher as \"features\", as características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_features = ['coluna_x1', 'coluna_x2', 'coluna_x3']\n",
    "\n",
    "X = data[data_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividir os dados para treino e validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X, val_X, train_y, val_y  = train_test_split(random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificar se existem valores faltantes\n",
    "\n",
    "Existem 3 maiores abordagens:\n",
    "1) Excluir linhas com dados faltantes\n",
    "2) Imputação - atribuir aos valores faltantes a média dos valores de cada coluna\n",
    "3) Extensão da imputação - faz a imputação padrão e também uma nova coluna para mostrar onde a imputação foi feita\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para saber qual a melhor abordagem, podemos testar uma a uma com uma função:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def  get_score (train_X, val_X, train_y, val_y):\n",
    "    model = DecisionTreeRegressor(random_state = 1)\n",
    "    model.fit(train_X, train_y)\n",
    "    preds = model.predict(val_X)\n",
    "    return mean_absolute_error(val_y, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeira abordagem - simplesmente excluir\n",
    "\n",
    "```python\n",
    "dados_nulos = []\n",
    "\n",
    "for coluna in train_X.columns:\n",
    "    if train_X[coluna].isnull().any():\n",
    "        # se houver valores NaN, adiciona a lista \n",
    "        dados_nulos.append(coluna)\n",
    "\n",
    "# removendo essas colunas\n",
    "train_X_reduzido = train_X.drop(dados_nulos, axis=1)\n",
    "val_X_reduzido = val_X.drop(dados_nulos, axis=1)\n",
    "\n",
    "print(\"MAE: \", get_score(train_X_reduzido, val_X_reduzido, train_y, val_y))\n",
    "```\n",
    "\n",
    "Segunda abordagem - imputação\n",
    "\n",
    "```python\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# imputação\n",
    "my_imputer = SimpleImputer()\n",
    "train_X_imput = pd.DataFrame(my_imputer.fit_transform(train_X))\n",
    "val_X_imput = pd.DataFrame(my_imputer.transform(val_X))\n",
    "\n",
    "# imputação removeu o nome das colunas\n",
    "## colocando de volta\n",
    "train_X_imput.columns = train_X.columns\n",
    "val_X_imput.columns = val_X.columns\n",
    "\n",
    "print(\"MAE: \", get_score(train_X_imput, val_X_imput, train_y, val_y))\n",
    "```\n",
    "\n",
    "Terceira abordagem - extensão da imputação\n",
    "\n",
    "```python\n",
    "# copiando os dados originais\n",
    "train_X_plus = train_X.copy()\n",
    "val_X_plus = val_X.copy()\n",
    "\n",
    "# fazendo uma nova coluna para os valores NaN\n",
    "for coluna in dados_nulos:\n",
    "    train_X_plus[coluna + '_was_missing'] = train_X_plus[coluna].isnull()\n",
    "    val_X_plus[coluna + '_was_missing'] = val_X_plus[coluna].isnull()\n",
    "\n",
    "# imputação\n",
    "my_imputer = SimpleImputer()\n",
    "imput_X_train_plus = pd.DataFrame(my_imputer.fit_transform(train_X_plus))\n",
    "imput_X_valid_plus = pd.DataFrame(my_imputer.transform(val_X_plus))\n",
    "\n",
    "# imputação removeu os nomes das colunas\n",
    "## renomeando elas...\n",
    "imput_X_train_plus.columns = train_X_plus.columns\n",
    "imput_X_valid_plus.columns = val_X_plus.columns\n",
    "\n",
    "print(\"MAE: \", get_score(imput_train_X, imput_val_X, train_y, val_y))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tendo em emnte qual abordagem é mais favorável ao estudo, optamos por ela e realizamos o respectivo algoritmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Construir o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "data_model = DecisionTreeRegressor(random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Ajustar modelo as variáveis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_model.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 3) Fazer previsões\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_predictions = data_model.predict(val_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Validar o modelo\n",
    "\n",
    "Pode ser validado pelo erro médio absoluto (Mean Absolute Error - MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "print(mean_absolute_error(val_y, val_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pré processar os dados de teste:\n",
    "\n",
    "1) Comparar os resultados obtidos com os resultados atuais/reais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Previsão: ', val_predictions[:5])\n",
    "print('Atual: ', val_y.head().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # imputação\n",
    "\n",
    "# final_X_test = pd.DataFrame(final_imputer.transform(X_test))\n",
    "\n",
    "# # previsões\n",
    "# preds_test = data_model.predict(final_X_test)\n",
    "\n",
    "# step_4.b.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Salvar as previsões em um arquivo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'Id': train_X.index, 'SalePrice': preds})\n",
    "output.to_csv('submissao.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
